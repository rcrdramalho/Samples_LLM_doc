import pandas as pd
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt

def create_decision_tree():
    """
    Main function to create and visualize a decision tree classifier
    based on weather conditions to predict an outcome (1 or 0).
    """
    
    data = {
        'Weather': ['Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Rainy', 'Cloudy', 'Sunny', 
                    'Cloudy', 'Rainy', 'Sunny', 'Rainy', 'Cloudy', 'Cloudy', 'Sunny'],
        'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 
                    'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Weak'],
        'Temperature': ['Hot', 'Hot', 'Mild', 'Mild', 'Cool', 'Cool', 'Mild', 
                        'Hot', 'Mild', 'Cool', 'Mild', 'Hot', 'Mild', 'Mild'],
        'Output': [0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1]
    }
    
    df = pd.DataFrame(data)
    print("Original Dataset:")
    print(df)
    print("\n")

    # Initialize LabelEncoders for each categorical feature.
    # LabelEncoder converts categorical labels into numerical format, 
    # which is required for machine learning algorithms.
    weather_encoder = LabelEncoder()
    wind_encoder = LabelEncoder()
    temp_encoder = LabelEncoder()
    
    # Apply Label Encoding to transform categorical columns into numerical equivalents.
    df['Weather_encoded'] = weather_encoder.fit_transform(df['Weather'])
    df['Wind_encoded'] = wind_encoder.fit_transform(df['Wind'])
    df['Temperature_encoded'] = temp_encoder.fit_transform(df['Temperature'])
    
    print("Weather classes:", list(weather_encoder.classes_))
    print("Wind classes:", list(wind_encoder.classes_))
    print("Temperature classes:", list(temp_encoder.classes_))
    print("\n")
    
    # Define features (X) and target (y) for the decision tree model.
    X = df[['Weather_encoded', 'Wind_encoded', 'Temperature_encoded']]
    y = df['Output']

    # Initialize the DecisionTreeClassifier with a maximum depth to prevent overfitting
    # and a random state for reproducibility.
    tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)

    # Train the decision tree classifier on the encoded features and target variable.
    tree_clf.fit(X, y)
    
    # Generate and print the textual representation of the decision tree rules.
    # The feature_names parameter makes the output more readable by using original feature names.
    tree_rules = export_text(tree_clf, 
                             feature_names=['Weather', 'Wind', 'Temperature'])
    print("Decision Tree Rules:")
    print(tree_rules)

    # Configure and display the visual representation of the decision tree.
    plt.figure(figsize=(12, 8))
    plot_tree(tree_clf, 
              feature_names=['Weather', 'Wind', 'Temperature'],
              class_names=['Unfavorable', 'Favorable'], # Labels for the target variable (0 and 1)
              filled=True, # Fills nodes with colors to indicate the majority class
              rounded=True) # Rounds the corners of the tree nodes
    plt.title("Decision Tree Visualization")
    plt.show()

    # Prepare new data for prediction.
    # The input data must be encoded in the same way as the training data.
    new_data1 = [[weather_encoder.transform(['Sunny'])[0], 
                  wind_encoder.transform(['Weak'])[0],
                  temp_encoder.transform(['Mild'])[0]]]
    prediction1 = tree_clf.predict(new_data1)
    print("\nPrediction for [Sunny, Weak, Mild]:", prediction1[0])

    new_data2 = [[weather_encoder.transform(['Rainy'])[0], 
                  wind_encoder.transform(['Strong'])[0],
                  temp_encoder.transform(['Cool'])[0]]]
    prediction2 = tree_clf.predict(new_data2)
    print("Prediction for [Rainy, Strong, Cool]:", prediction2[0])
